#pragma once

#include "stuff/TensorIndexShape.hpp"
#include "stuff/TensorIndex.hpp"

#include <vector>

// !!!
#include <type_traits>
#include <optional>

// for ostream, see https://en.cppreference.com/w/cpp/feature_test
#ifdef __cpp_lib_char8_t
#include <ostream>
#endif // __cpp_lib_char8_t

// !!!
#include "tmp/string_utils.hpp"
#include "stuff/init_list_utils.hpp"
#include "stuff/reshaper.hpp"

namespace lc
{
	// TODO remove
	template <class T>
	class TMP_IMPL : public T {};

	// TODO move
	template <TShapeType _Shape, class Ty>
	struct TShape2InitList {
		using initializer_list = std::initializer_list<typename TShape2InitList<typename _Shape::Tail, Ty>::initializer_list>;
	};
	template <class Ty>
	struct TShape2InitList<TShape<>, Ty> {
		using initializer_list = Ty;
	};

	//template <template <class T> class _TImpl, class Ty, size_t _rank, TensorShape<_rank> _shape>
	//struct FixedTensorContainerData;

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
		//requires (contains_variable_size(_shape))
	struct FixedTensorContainerData_1//<_TImpl, Ty, _rank, _shape>
	{
		using Shape = TensorShape<_Shape::shape.rank()>;
		static inline constexpr Shape staticShape = _Shape::shape;
		inline static constexpr size_t variableSizeCount = variable_size_dims_count(staticShape);
		constexpr Shape shape() const noexcept;
		static constexpr size_t rank() { return staticShape.rank(); }

		constexpr Ty* data() { return m_data.data(); }
		constexpr const Ty* data() const { return m_data.data(); }

		constexpr void reshape(const Shape& shape);

		constexpr size_t offsetOf(const std::span<const size_t, rank()>& indexes) const;

		constexpr FixedTensorContainerData_1(const typename TShape2InitList<_Shape, Ty>::initializer_list& initList) {
			using SubT = typename TShape2InitList<_Shape, Ty>::initializer_list::value_type;
			const auto shape = toInitShape<TensorShape, rank(), SubT>(initList);

			this->reshape(shape);
			iterateNestedInitList<TensorIndex, rank(), SubT>(initList, [this](const auto& idx, const auto& value) constexpr {
				this->data()[this->offsetOf(idx)] = value;
			});
		}

	private:

		static constexpr size_t freeSizeInternalIndex(size_t d);

		static constexpr size_t freeSizeInternalIndex2index(size_t d);

		constexpr size_t& freeSizeAt(size_t d);

		constexpr const size_t& freeSizeAt(size_t d) const;

		static constexpr bool is_dim_assignable(size_t index);

		static constexpr bool is_dim_ok_for_reshape(const Shape& shape);

		constexpr void mem_shape(const Shape& shape);

		//template <size_t _rank2>
		//constexpr void reshape_data(const std::span<size_t, _rank2>& shapeIn, const std::span<size_t, _rank2>& shapeOut, Ty* dataIn, Ty* dataOut);

	private:
		// TODO {#vector-optimization} the last part of the shape that is static, should be threated separately, for example:
		// if shape is { 3, {}, 3, 3, {}, 5, 5 }
		// we shoudl actually store a vector of a 5x5 matrix with dim { 3, {}, 3, 3, {} }. In this way,
		// we can save 1 size_t because it will be encoded in the std::vector size. For example,
		// if the user requires a tensor of shape { {} } it should behave exaclty like std::vector<>
		// by inheriting from it, while { {}, 5 } could designate a matrix with 5 columns and the container
		// should behave like a std::vector of Vec5.
		// Remember that we have to remove the FixedRankShapeHolder and unify these two calsses since, if we inherit
		// from two calsses, aditional space would be likely to be used.
		std::vector<Ty> m_data;

		size_t m_freeSizes[variableSizeCount] = {};
	};

	// this is a temporary specialization, see #vector-optimization
	template <template <class T> class _TImpl, class Ty>
	struct FixedTensorContainerData_1<_TImpl, Ty, TShape<variable_size>> : std::vector<double>
	{
		using Shape = TensorShape<1>;
		static inline constexpr Shape staticShape = TShape<variable_size>::shape;
		inline static constexpr size_t variableSizeCount = 1;
		constexpr Shape shape() const noexcept { Shape shape; shape[0] = this->size(); return shape; }
		static constexpr size_t rank() { return 1; }

		constexpr void reshape(const Shape& shape) {
			assert(shape[0].is_fixed());
			this->resize(shape[0].is_fixed() ? shape[0].value() : 0);
		}

		constexpr size_t offsetOf(const std::span<const size_t, 1>& indexes) const { return indexes[0]; }
	};

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
		//requires (!contains_variable_size(_shape))
	struct FixedTensorContainerData_2//<_TImpl, Ty, _rank, _shape>
	{
		using Shape = TensorShape<_Shape::shape.rank()>;
		inline static constexpr size_t variableSizeCount = 0;
		static inline constexpr Shape staticShape = _Shape::shape;
		static constexpr auto shape() noexcept { return staticShape; }
		static constexpr size_t rank() { return staticShape.rank(); }

		constexpr Ty* data() { return m_data.data(); }
		constexpr const Ty* data() const { return m_data.data(); }

		static constexpr size_t offsetOf(const std::span<const size_t, rank()>& indexes);

	private:
		std::array<Ty, elemCount(staticShape)> m_data;
	};

	// TODO intellisense doesn't like _S
	/*template <template <class T> class _TImpl, class Ty, size_t _S>
	struct FixedTensorContainerData_2<_TImpl, Ty, TShape<_S>> : std::array<Ty, _S>
	{
		using Shape = TensorShape<1>;
		inline static constexpr size_t variableSizeCount = 0;
		static inline constexpr Shape staticShape = TShape<_S>::shape;
		static constexpr auto shape() noexcept { return staticShape; }
		static constexpr size_t rank() { return 1; }

		static constexpr size_t offsetOf(const std::span<size_t, rank()>& indexes) { return indexes[0]; }

	private:
	};*/

	template <TensorIndexShape ShapeL, ShapeL shape>
	inline constexpr bool contains_variable_size_v = contains_variable_size(shape);

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	//struct FixedTensorContainer : FixedTensorContainerProvider<::lc::contains_variable_size(_shape)>::Container<_TImpl, Ty, _rank, _shape>
	//struct FixedTensorContainer : FixedTensorContainerData<_TImpl, Ty, _rank, _shape>
	struct FixedTensorContainer : std::conditional_t<contains_variable_size(_Shape::shape), FixedTensorContainerData_1<_TImpl, Ty, _Shape>, FixedTensorContainerData_2<_TImpl, Ty, _Shape>>
	{
		using Base = std::conditional_t<contains_variable_size(_Shape::shape), FixedTensorContainerData_1<_TImpl, Ty, _Shape>, FixedTensorContainerData_2<_TImpl, Ty, _Shape>>;

		using Base::Base;

		//static inline constexpr bool ccc = contains_variable_size(_shape);
		using Index = std::array<size_t, _Shape::shape.rank()>;
		using IndexSpan = std::span<size_t, _Shape::shape.rank()>;
		using CIndexSpan = std::span<const size_t, _Shape::shape.rank()>;
		using PartialIndex = std::array<TensorDim, _Shape::shape.rank()>;

		using value_type = Ty;

		constexpr Ty& operator[](const Index& idx) {
			return this->data()[this->offsetOf(idx)];
		}

		constexpr const Ty& operator[](const Index& idx) const {
			return this->data()[this->offsetOf(idx)];
		}

		constexpr Ty& operator[](size_t idx) requires (_Shape::shape.rank() == 1) {
			return this->data()[idx];
		}
	};

	template <class T> struct is_FixedTensorContainer : std::false_type {};
	template <template <class T> class _TImpl, class Ty, TShapeType _Shape> struct is_FixedTensorContainer<FixedTensorContainer<_TImpl, Ty, _Shape>> : std::true_type {};

	template <class T>
	concept FixedTensorContainerType = is_FixedTensorContainer<T>::value;

	template <class T, size_t N>
	concept NdFixedTensorContainerType = FixedTensorContainerType<T> && (T::rank() == N);
	template <class T>
	concept MonodimensionalFixedTensorContainerType = NdFixedTensorContainerType<T, 1>;
	template <class T>
	concept BidimensionalFixedTensorContainerType = NdFixedTensorContainerType<T, 2>;
}


#ifdef __cpp_lib_char8_t

template <lc::MonodimensionalFixedTensorContainerType Container>
std::ostream& operator<<(std::ostream& os, const Container& tensor) {
	os << "( ";
	for (auto it = tensor.begin(); it != tensor.end(); ++it)
		os << *it << (std::next(it) == tensor.end() ? " " : ", ");
	os << ")";
	return os;
}

namespace lc::tmp_priv
{
	struct stream_matrix_options
	{
		bool hideZeros = false;
		bool framed = true;
		std::string separator = " ";
	};

	template <lc::BidimensionalFixedTensorContainerType T>
	void stream_matrix(std::ostream& os, const T& tensor, const stream_matrix_options& options = {})
	{
		using Ty = typename T::value_type;

		auto shape = tensor.shape();
		const auto N = shape[0].value();
		const auto M = shape[1].value();

		if (N == 0)
		{
			os << "( )";
			return;
		}
		/* TODO if (N == 1)
		{
			os << tensor[1];
			return os;
		}*/

		// OLD, problems if elements have different sizes
		if constexpr (0)
			for (int i = 0; i < N; ++i)
			{
				os << (i == 0 ? "/ " : ((i + 1) == N ? "\\ " : "| "));
				for (int j = 0; j < M; ++j)
					os << tensor[i][j] << " ";
				os << (i == 0 ? "\\\n" : ((i + 1) == N ? "/" : "|\n"));
			}
		if constexpr (1)
		{
			using namespace std::string_literals;

			std::vector<std::string> datacolumns(M);
			{
				for (int i = 0; i < N; ++i)
					for (int j = 0; j < M; ++j)
						// TODO columns[j + 1] += lc::stream_to_string(tensor[i][j]) + ' ' + ((i + 1 == N) ? "" : "\n");
						datacolumns[j + 1] += (
							(tensor[{(size_t)i, (size_t)j}] == Ty() && options.hideZeros) ?
							"." :
							" "s + lc::stream_to_string(tensor[{(size_t)i, (size_t)j}])) + ((i + 1 == N) ? "" : "\n")
						;
			}

			if (options.framed)
			{
				std::string leftColumn, rightColumn;
				for (int i = 0; i < N; ++i)
				{
					if (N == 1)
					{
						leftColumn += "<";
						rightColumn += " >";
						break;
					}

					leftColumn += (i == 0 ? "/\n" : (i == N - 1 ? "\\" : "|"));
					rightColumn += (i == 0 ? " \\\n" : (i == N - 1 ? " /" : " |"));
				}
				datacolumns.insert(datacolumns.begin(), leftColumn);
				datacolumns.insert(datacolumns.end(), rightColumn);
			}

			os << lc::put_beside(datacolumns, lc::TerminalHAlign::Right);
		}
	}
}
namespace lc
{
	template <template <class T> class _TImpl, class T, TensorDim _N, TensorDim _M>
	struct tmp_matrix_hide_zeors {

		using Mat = lc::FixedTensorContainer<_TImpl, T, TShape<_N, _M>>;

		tmp_matrix_hide_zeors(const Mat& mat) : matrix(mat) {};

		const Mat& matrix;
	};

	template <template <class T> class _TImpl, class T, TensorDim _N, TensorDim _M>
	auto hide_zeors(const lc::FixedTensorContainer<_TImpl, T, TShape<_N, _M>>& mat) {
		return tmp_matrix_hide_zeors<_TImpl, T, _N, _M>(mat);
	}
}

template <lc::BidimensionalFixedTensorContainerType T>
std::ostream& operator<<(std::ostream& os, const T& tensor)
{
	lc::tmp_priv::stream_matrix(os, tensor);
	return os;
}

template <template <class T> class _TImpl, class T, lc::TensorDim _N, lc::TensorDim _M>
std::ostream& operator<<(std::ostream& os, const lc::tmp_matrix_hide_zeors<_TImpl, T, _N, _M>& tensor)
{
	lc::tmp_priv::stream_matrix(os, tensor.matrix, { .hideZeros = true });
	return os;
}

#endif // __cpp_lib_char8_t

// ================================================================================================================================
// ================================================================================================================================
//                                                             IMPL
// ================================================================================================================================
// ================================================================================================================================

namespace lc
{
	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	inline constexpr typename FixedTensorContainerData_1<_TImpl, Ty, _Shape>::Shape FixedTensorContainerData_1<_TImpl, Ty, _Shape>::shape() const noexcept
	{
		auto shape = staticShape;
		for (size_t i = 0; i < variableSizeCount; ++i)
			shape[this->freeSizeInternalIndex2index(i)] = m_freeSizes[i];
		return shape;
	}

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	inline constexpr void FixedTensorContainerData_1<_TImpl, Ty, _Shape>::reshape(const Shape& _shape)
	{
		const Shape shape = [&]() constexpr {
			Shape shape = {};
			for (size_t i = 0; i < shape.rank(); ++i)
				shape[i] = _shape[i].is_fixed() ? _shape[i].value() : this->shape()[i].value();
			return shape;
		}();

		const size_t oldSize = m_data.size();
		const size_t newSize = elemCount(shape);
		const bool preResize = newSize > oldSize;

		if (preResize) m_data.resize(newSize); {
			const auto currshape = this->shape();
			std::array<size_t, staticShape.rank()> arrCurrShape; for (size_t i = 0; i < staticShape.rank(); ++i) arrCurrShape[i] = currshape[i].value();
			std::array<size_t, staticShape.rank()> arrNewShape; for (size_t i = 0; i < staticShape.rank(); ++i) arrNewShape[i] = shape[i].value();
			//this->reshape_data<staticShape.rank()>(arrCurrShape, arrNewShape, this->data(), this->data());
			TensorDataReshaper<rank()>::template reshape_data<Ty>(arrCurrShape, arrNewShape, this->data(), this->data());

			// store the new shape
			this->mem_shape(shape);
		} if (!preResize) m_data.resize(newSize);
	}

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	inline constexpr size_t FixedTensorContainerData_1<_TImpl, Ty, _Shape>::offsetOf(const std::span<const size_t, rank()>& indexes) const
	{

		size_t off = 0;
		size_t prod = 1;

		for (size_t _i = rank(); _i > 0; --_i)
		{
			const auto i = _i - 1;

			off += indexes[i] * prod;
			prod *= this->shape()[i].value();
		}

		return off;
	}

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	inline constexpr size_t FixedTensorContainerData_1<_TImpl, Ty, _Shape>::freeSizeInternalIndex(size_t d)
	{
		// TODO with external function, near variable_size_dims_count
		return std::count_if(
			staticShape.begin(),
			staticShape.begin() + std::min<size_t>(d, std::ranges::size(staticShape)),
			[](const TensorDim& dim) { return dim.is_variable(); }
		);
	}

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	inline constexpr size_t FixedTensorContainerData_1<_TImpl, Ty, _Shape>::freeSizeInternalIndex2index(size_t d)
	{
		size_t count = 0;
		for (size_t i = 0; i < staticShape.size(); ++i)
			if (staticShape[i].is_variable())
			{
				if (count == d)
					return i;
				else
					++count;
			}
		assert(0);
		return 0; // TODO error
	}

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	inline constexpr size_t& FixedTensorContainerData_1<_TImpl, Ty, _Shape>::freeSizeAt(size_t d)
	{
		return m_freeSizes[this->freeSizeInternalIndex(d)];
	}

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	inline constexpr const size_t& FixedTensorContainerData_1<_TImpl, Ty, _Shape>::freeSizeAt(size_t d) const
	{
		return m_freeSizes[this->freeSizeInternalIndex(d)];
	}

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	inline constexpr bool FixedTensorContainerData_1<_TImpl, Ty, _Shape>::is_dim_assignable(size_t index)
	{
		return staticShape[index].is_variable();
	}

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	inline constexpr bool FixedTensorContainerData_1<_TImpl, Ty, _Shape>::is_dim_ok_for_reshape(const Shape& shape)
	{
		for (size_t i = 0; i < staticShape.rank(); ++i)
		{
			const TensorDim& dim = shape[i];
			const TensorDim& staticDim = staticShape[i];

			// check for conflicts
			if (dim.is_fixed() && staticDim.is_fixed())
				if (dim.value() != staticDim.value())
					return false;

			// if assignable
			//if (is_dim_assignable(i))
			//	if (!dim.is_fixed())
			//		return false;
		}

		return true;
	}

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	inline constexpr void FixedTensorContainerData_1<_TImpl, Ty, _Shape>::mem_shape(const Shape& shape)
	{
		assert(this->is_dim_ok_for_reshape(shape));

		for (size_t i = 0; i < staticShape.rank(); ++i) {
			const TensorDim& dim = shape[i];
			const TensorDim& staticDim = staticShape[i];

			// if assignable
			if (is_dim_assignable(i))
				freeSizeAt(i) = dim.is_fixed() ? dim.value() : 0;
		}
	}

	template <template <class T> class _TImpl, class Ty, TShapeType _Shape>
	constexpr size_t FixedTensorContainerData_2<_TImpl, Ty, _Shape>::offsetOf(const std::span<const size_t, rank()>& indexes)
	{

		size_t off = 0;
		size_t prod = 1;

		for (size_t _i = rank(); _i > 0; ++_i)
		{
			const auto i = _i - 1;

			off += indexes[i] * prod;
			prod *= shape()[i].value();
		}

		return off;
	}
}